{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPSz+UGwbADyzEP5PtuWuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopinathak-geek/Image-classification-with-pytorch/blob/main/novo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gopinathak-geek/novozymes-enzyme-stability-prediction.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp5Qq3_rNErj",
        "outputId": "f0aa1223-740e-4d39-bd20-271a673480c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'novozymes-enzyme-stability-prediction'...\n",
            "remote: Enumerating objects: 29516, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 29516 (delta 53), reused 141 (delta 52), pack-reused 29373\u001b[K\n",
            "Receiving objects: 100% (29516/29516), 554.63 MiB | 21.64 MiB/s, done.\n",
            "Resolving deltas: 100% (29188/29188), done.\n",
            "Checking out files: 100% (29408/29408), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fBLMXeHpv1Ze",
        "outputId": "d9a15b06-7133-43f4-abb4-383efc88c58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 13.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.21.6)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.1%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (873 kB)\n",
            "\u001b[K     |████████████████████████████████| 873 kB 8.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 70.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=34662167dac27fd244ea373b88f82b7b4702a0891fe4044d8fb7efc4699c0309\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_hRzYI2CRP",
        "outputId": "eb4195d3-f0a4-42f5-f0a8-b5308687eafe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.3 MB 95.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Dataset, download_url, DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mdyPJ0ra2bcR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NovoDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(NovoDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "\n",
        "        if self.test:\n",
        "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
        "        else:\n",
        "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0])\n",
        "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            mol_obj = Chem.MolFromSequence(mol[\"protein_sequence\"])\n",
        "            ph = mol[\"pH\"]\n",
        "            \n",
        "            # Get node features\n",
        "            node_feats = self._get_node_features(mol_obj, ph)\n",
        "            \n",
        "            # Get edge features\n",
        "            edge_feats = self._get_edge_features(mol_obj)\n",
        "            \n",
        "            # Get adjacency info\n",
        "            edge_index = self._get_adjacency_info(mol_obj)\n",
        "            \n",
        "            \n",
        "            if self.test:\n",
        "                #Create data object for testing data\n",
        "                data = Data(x=node_feats, edge_index=edge_index, edge_attr=edge_feats) \n",
        "                \n",
        "                #save test data\n",
        "                torch.save(data, osp.join(self.processed_dir, f'data_test_{index}.pt'))\n",
        "            else:\n",
        "                # Get labels info\n",
        "                label = self._get_labels(mol[\"tm\"])\n",
        "                \n",
        "                #Create data object for training data\n",
        "                data = Data(x=node_feats, edge_index=edge_index, edge_attr=edge_feats, y=label) \n",
        "                \n",
        "                #save train data\n",
        "                torch.save(data, osp.join(self.processed_dir, f'data_{index}.pt'))\n",
        "        \n",
        "    def _get_node_features(self, mol, ph):\n",
        "        \"\"\" \n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of Nodes, Node Feature size]\n",
        "        \"\"\"\n",
        "        all_node_feats = []\n",
        "    \n",
        "        for atom in mol.GetAtoms():\n",
        "            node_feats = []\n",
        "            # Feature 1: Atomic number        \n",
        "            node_feats.append(atom.GetAtomicNum())\n",
        "            # Feature 2: Atom degree\n",
        "            node_feats.append(atom.GetDegree())\n",
        "            # Feature 3: Formal charge\n",
        "            node_feats.append(atom.GetFormalCharge())\n",
        "            # Feature 4: Hybridization\n",
        "            node_feats.append(atom.GetHybridization())\n",
        "            # Feature 5: Aromaticity\n",
        "            node_feats.append(atom.GetIsAromatic())\n",
        "            # Feature 6: Total Num Hs\n",
        "            node_feats.append(atom.GetTotalNumHs())\n",
        "            # Feature 7: Radical Electrons\n",
        "            node_feats.append(atom.GetNumRadicalElectrons())\n",
        "            # Feature 8: In Ring\n",
        "            node_feats.append(atom.IsInRing())\n",
        "            # Feature 9: Chirality\n",
        "            node_feats.append(atom.GetChiralTag())\n",
        "            # Feature 10: ph\n",
        "            node_feats.append(ph)\n",
        "    \n",
        "            # Append node features to matrix\n",
        "            all_node_feats.append(node_feats)\n",
        "\n",
        "        all_node_feats = np.asarray(all_node_feats)\n",
        "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_edge_features(self, mol):\n",
        "        \"\"\" \n",
        "        This will return a matrix / 2d array of the shape\n",
        "        [Number of edges, Edge Feature size]\n",
        "        \"\"\"\n",
        "        all_edge_feats = []\n",
        "\n",
        "        for bond in mol.GetBonds():\n",
        "            edge_feats = []\n",
        "            # Feature 1: Bond type (as double)\n",
        "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
        "            # Feature 2: Rings\n",
        "            edge_feats.append(bond.IsInRing())\n",
        "            # Append node features to matrix (twice, per direction)\n",
        "            all_edge_feats += [edge_feats, edge_feats]\n",
        "\n",
        "        all_edge_feats = np.asarray(all_edge_feats)\n",
        "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
        "\n",
        "    def _get_adjacency_info(self, mol):\n",
        "        \"\"\"\n",
        "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
        "        but we want to be sure that the order of the indices\n",
        "        matches the order of the edge features\n",
        "        \"\"\"\n",
        "        edge_indices = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "            edge_indices += [[i, j], [j, i]]\n",
        "\n",
        "        edge_indices = torch.tensor(edge_indices)\n",
        "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
        "        return edge_indices\n",
        "\n",
        "    def _get_labels(self, label):\n",
        "        return torch.tensor(label, dtype=torch.float)\n",
        "    \n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(osp.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))   \n",
        "        return data"
      ],
      "metadata": {
        "id": "4BViwMej2hzj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NovoDataset(root=\"novozymes-enzyme-stability-prediction/data/\", filename=\"training.csv\")\n",
        "test_dataset = NovoDataset(root=\"novozymes-enzyme-stability-prediction/data/\", filename=\"testing.csv\", test=True)"
      ],
      "metadata": {
        "id": "MbhAqZRI75js"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
        "from torch_geometric.nn import TransformerConv, TopKPooling , GCNConv, TopKPooling, global_mean_pool\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
      ],
      "metadata": {
        "id": "J1gfvgZ4Mmrz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "training_data, validation_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "KCSx6PfgMtAp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCHSIZE = 128\n",
        "OUTPUT = 1\n",
        "EMBEDDING_SIZE = 64"
      ],
      "metadata": {
        "id": "7kDtsPq9MzSp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=training_data, batch_size=BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(dataset=validation_data, batch_size=BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "XBHg8ShuM3ks"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # Init parent\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # GCN layers\n",
        "        self.initial_conv = GCNConv(10, EMBEDDING_SIZE)\n",
        "        self.conv1 = GCNConv(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
        "        self.conv2 = GCNConv(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
        "        self.conv3 = GCNConv(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = Linear(EMBEDDING_SIZE*2, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # First Conv layer\n",
        "        hidden = self.initial_conv(x, edge_index)\n",
        "        hidden = torch.tanh(hidden)\n",
        "\n",
        "        # Other Conv layers\n",
        "        hidden = self.conv1(hidden, edge_index)\n",
        "        hidden = torch.tanh(hidden)\n",
        "        hidden = self.conv2(hidden, edge_index)\n",
        "        hidden = torch.tanh(hidden)\n",
        "        hidden = self.conv3(hidden, edge_index)\n",
        "        hidden = torch.tanh(hidden)\n",
        "          \n",
        "        # Global Pooling (stack different aggregations)\n",
        "        hidden = torch.cat([gmp(hidden, batch_index), \n",
        "                            gap(hidden, batch_index)], dim=1)\n",
        "\n",
        "        # Apply a final (linear) classifier.\n",
        "        out = self.out(hidden)\n",
        "\n",
        "        return out, hidden"
      ],
      "metadata": {
        "id": "LE9CI68LOYM6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN()\n",
        "model.to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 20\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "KrrSXDNnOaGA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n"
      ],
      "metadata": {
        "id": "IzasCBoJOfBr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_score_history = []\n",
        "training_losses_history = []\n",
        "validation_score_history = []\n",
        "validation_losses_history = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    training_score = []\n",
        "    training_loss = []\n",
        "    for batch in train_loader:\n",
        "        batch.to(DEVICE)\n",
        "        #==========Forward pass===============\n",
        "        pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
        "        loss = criterion(pred, torch.Tensor(batch.y))\n",
        "        #==========backward pass==============\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_result = stats.spearmanr(pred.detach().cpu().numpy(), batch.y.cpu().numpy())\n",
        "        training_score.append(train_result.correlation)\n",
        "        training_loss.append(loss.item())\n",
        "    \n",
        "    training_scores = np.mean(training_score)\n",
        "    training_losses = np.mean(training_loss)\n",
        "\n",
        "    validation_score = []\n",
        "    validation_loss = []\n",
        "    for batch in valid_loader:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            batch.to(DEVICE)\n",
        "            val_preds, val_embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
        "            val_loss = criterion(val_preds, torch.Tensor(batch.y))\n",
        "            \n",
        "            val_result = stats.spearmanr(val_preds.detach().cpu().numpy(), batch.y.cpu().numpy())\n",
        "            validation_score.append(val_result.correlation)\n",
        "            validation_loss.append(val_loss.item())\n",
        "        \n",
        "    validation_scores = np.mean(validation_score)\n",
        "    validation_losses = np.mean(validation_loss)\n",
        "        \n",
        "training_score_history.append(training_scores)\n",
        "training_losses_history.append(training_losses)\n",
        "validation_score_history.append(validation_scores)\n",
        "validation_losses_history.append(validation_losses)\n",
        "print(f'{epoch+1:03} EPOCH - Training score : {np.mean(training_scores):.5f} | Validation score : {np.mean(validation_scores):.5f} | Training loss : {np.mean(training_losses):.5f} | Validation loss : {np.mean(validation_losses):.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hog4XsTDOiYL",
        "outputId": "fd1e5f85-5d2a-47a7-d406-86810a8d71e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2da5f29f70>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2da5f29f70>  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
            "    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
            "        if w.is_alive():self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
            "        if w.is_alive():\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError\n",
            ": AssertionErrorcan only test a child process: can only test a child process\n",
            "\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2da5f29f70>\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f2da5f29f70>Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
            "\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
            "self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
            "        if w.is_alive():self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
            "\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "AssertionError: can only test a child process    \n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        }
      ]
    }
  ]
}